{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' ResNet Implementation '''\n",
        "''' code reference from https://github.com/kuangliu/pytorch-cifar '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ChcfbHyaBB2D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "c7e183e0ea0142debf3be71f9c119172",
            "5bd88bb3c6be4c7d89c47492e2cd32f8",
            "4530906ace054be1a6cd62884698b235",
            "3baa6f62b034472e803a6ba58e4440d1",
            "370bab8a7834477d92bf69b4d419d8c6",
            "2fb416e92e2a4f78a8fb625e6b89026d",
            "4307047c16b248a8a5d67c62459befdb",
            "dbc819a692fb4a7f8bcb67713e323b02",
            "e050d161f3cb412aa677ababd693ebff",
            "75451fb9889d460badc555832b180867",
            "b8528f587020461d95979131c341f1ab"
          ]
        },
        "id": "EM5eLlVgBZpN",
        "outputId": "7c23263e-bc6c-48df-f169-1b6c229e629c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7e183e0ea0142debf3be71f9c119172",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-jzhSHUxIYst"
      },
      "outputs": [],
      "source": [
        "# ResNet\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fsD96QmmJW1P"
      },
      "outputs": [],
      "source": [
        "net = ResNet18()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YDEhN1MRJa11"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VVHBF64JbBe",
        "outputId": "1b96b8a8-00f6-4d9f-c391-8916a83ad7e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            "train\n",
            "Loss: 1.920 | Acc: 30.816% (15408/50000)\n",
            "test\n",
            "Loss: 1.590 | Acc: 40.110% (4011/10000)\n",
            "\n",
            "Epoch: 1\n",
            "train\n",
            "Loss: 1.397 | Acc: 48.568% (24284/50000)\n",
            "test\n",
            "Loss: 1.222 | Acc: 56.470% (5647/10000)\n",
            "\n",
            "Epoch: 2\n",
            "train\n",
            "Loss: 1.105 | Acc: 60.414% (30207/50000)\n",
            "test\n",
            "Loss: 1.062 | Acc: 62.050% (6205/10000)\n",
            "\n",
            "Epoch: 3\n",
            "train\n",
            "Loss: 0.933 | Acc: 66.886% (33443/50000)\n",
            "test\n",
            "Loss: 0.859 | Acc: 69.730% (6973/10000)\n",
            "\n",
            "Epoch: 4\n",
            "train\n",
            "Loss: 0.787 | Acc: 72.418% (36209/50000)\n",
            "test\n",
            "Loss: 0.790 | Acc: 73.210% (7321/10000)\n",
            "\n",
            "Epoch: 5\n",
            "train\n",
            "Loss: 0.668 | Acc: 76.922% (38461/50000)\n",
            "test\n",
            "Loss: 0.689 | Acc: 76.620% (7662/10000)\n",
            "\n",
            "Epoch: 6\n",
            "train\n",
            "Loss: 0.596 | Acc: 79.460% (39730/50000)\n",
            "test\n",
            "Loss: 0.661 | Acc: 77.650% (7765/10000)\n",
            "\n",
            "Epoch: 7\n",
            "train\n",
            "Loss: 0.551 | Acc: 81.048% (40524/50000)\n",
            "test\n",
            "Loss: 0.710 | Acc: 76.030% (7603/10000)\n",
            "\n",
            "Epoch: 8\n",
            "train\n",
            "Loss: 0.521 | Acc: 81.870% (40935/50000)\n",
            "test\n",
            "Loss: 0.633 | Acc: 78.450% (7845/10000)\n",
            "\n",
            "Epoch: 9\n",
            "train\n",
            "Loss: 0.497 | Acc: 82.858% (41429/50000)\n",
            "test\n",
            "Loss: 0.613 | Acc: 78.660% (7866/10000)\n",
            "\n",
            "Epoch: 10\n",
            "train\n",
            "Loss: 0.476 | Acc: 83.732% (41866/50000)\n",
            "test\n",
            "Loss: 0.538 | Acc: 81.600% (8160/10000)\n",
            "\n",
            "Epoch: 11\n",
            "train\n",
            "Loss: 0.461 | Acc: 84.152% (42076/50000)\n",
            "test\n",
            "Loss: 0.805 | Acc: 75.240% (7524/10000)\n",
            "\n",
            "Epoch: 12\n",
            "train\n",
            "Loss: 0.446 | Acc: 84.636% (42318/50000)\n",
            "test\n",
            "Loss: 0.610 | Acc: 80.140% (8014/10000)\n",
            "\n",
            "Epoch: 13\n",
            "train\n",
            "Loss: 0.437 | Acc: 84.948% (42474/50000)\n",
            "test\n",
            "Loss: 0.666 | Acc: 77.850% (7785/10000)\n",
            "\n",
            "Epoch: 14\n",
            "train\n",
            "Loss: 0.425 | Acc: 85.502% (42751/50000)\n",
            "test\n",
            "Loss: 0.540 | Acc: 81.330% (8133/10000)\n",
            "\n",
            "Epoch: 15\n",
            "train\n",
            "Loss: 0.413 | Acc: 85.758% (42879/50000)\n",
            "test\n",
            "Loss: 0.479 | Acc: 83.660% (8366/10000)\n",
            "\n",
            "Epoch: 16\n",
            "train\n",
            "Loss: 0.403 | Acc: 86.268% (43134/50000)\n",
            "test\n",
            "Loss: 0.507 | Acc: 82.810% (8281/10000)\n",
            "\n",
            "Epoch: 17\n",
            "train\n",
            "Loss: 0.396 | Acc: 86.648% (43324/50000)\n",
            "test\n",
            "Loss: 0.527 | Acc: 81.720% (8172/10000)\n",
            "\n",
            "Epoch: 18\n",
            "train\n",
            "Loss: 0.398 | Acc: 86.598% (43299/50000)\n",
            "test\n",
            "Loss: 0.504 | Acc: 82.670% (8267/10000)\n",
            "\n",
            "Epoch: 19\n",
            "train\n",
            "Loss: 0.383 | Acc: 86.750% (43375/50000)\n",
            "test\n",
            "Loss: 0.559 | Acc: 80.760% (8076/10000)\n",
            "\n",
            "Epoch: 20\n",
            "train\n",
            "Loss: 0.388 | Acc: 86.712% (43356/50000)\n",
            "test\n",
            "Loss: 0.451 | Acc: 85.030% (8503/10000)\n",
            "\n",
            "Epoch: 21\n",
            "train\n",
            "Loss: 0.377 | Acc: 87.124% (43562/50000)\n",
            "test\n",
            "Loss: 0.463 | Acc: 84.790% (8479/10000)\n",
            "\n",
            "Epoch: 22\n",
            "train\n",
            "Loss: 0.376 | Acc: 87.256% (43628/50000)\n",
            "test\n",
            "Loss: 0.586 | Acc: 81.220% (8122/10000)\n",
            "\n",
            "Epoch: 23\n",
            "train\n",
            "Loss: 0.370 | Acc: 87.422% (43711/50000)\n",
            "test\n",
            "Loss: 0.769 | Acc: 77.470% (7747/10000)\n",
            "\n",
            "Epoch: 24\n",
            "train\n",
            "Loss: 0.360 | Acc: 87.702% (43851/50000)\n",
            "test\n",
            "Loss: 0.744 | Acc: 76.270% (7627/10000)\n",
            "\n",
            "Epoch: 25\n",
            "train\n",
            "Loss: 0.359 | Acc: 87.824% (43912/50000)\n",
            "test\n",
            "Loss: 0.483 | Acc: 84.180% (8418/10000)\n",
            "\n",
            "Epoch: 26\n",
            "train\n",
            "Loss: 0.356 | Acc: 87.900% (43950/50000)\n",
            "test\n",
            "Loss: 0.440 | Acc: 85.390% (8539/10000)\n",
            "\n",
            "Epoch: 27\n",
            "train\n",
            "Loss: 0.350 | Acc: 88.046% (44023/50000)\n",
            "test\n",
            "Loss: 0.608 | Acc: 80.280% (8028/10000)\n",
            "\n",
            "Epoch: 28\n",
            "train\n",
            "Loss: 0.346 | Acc: 88.142% (44071/50000)\n",
            "test\n",
            "Loss: 0.773 | Acc: 76.690% (7669/10000)\n",
            "\n",
            "Epoch: 29\n",
            "train\n",
            "Loss: 0.347 | Acc: 87.978% (43989/50000)\n",
            "test\n",
            "Loss: 0.503 | Acc: 83.100% (8310/10000)\n",
            "\n",
            "Epoch: 30\n",
            "train\n",
            "Loss: 0.344 | Acc: 88.208% (44104/50000)\n",
            "test\n",
            "Loss: 0.605 | Acc: 79.720% (7972/10000)\n",
            "\n",
            "Epoch: 31\n",
            "train\n",
            "Loss: 0.337 | Acc: 88.382% (44191/50000)\n",
            "test\n",
            "Loss: 0.429 | Acc: 85.640% (8564/10000)\n",
            "\n",
            "Epoch: 32\n",
            "train\n",
            "Loss: 0.334 | Acc: 88.596% (44298/50000)\n",
            "test\n",
            "Loss: 0.513 | Acc: 83.320% (8332/10000)\n",
            "\n",
            "Epoch: 33\n",
            "train\n",
            "Loss: 0.335 | Acc: 88.518% (44259/50000)\n",
            "test\n",
            "Loss: 0.467 | Acc: 84.730% (8473/10000)\n",
            "\n",
            "Epoch: 34\n",
            "train\n",
            "Loss: 0.328 | Acc: 88.922% (44461/50000)\n",
            "test\n",
            "Loss: 0.451 | Acc: 85.210% (8521/10000)\n",
            "\n",
            "Epoch: 35\n",
            "train\n",
            "Loss: 0.328 | Acc: 88.834% (44417/50000)\n",
            "test\n",
            "Loss: 0.561 | Acc: 81.740% (8174/10000)\n",
            "\n",
            "Epoch: 36\n",
            "train\n",
            "Loss: 0.325 | Acc: 88.988% (44494/50000)\n",
            "test\n",
            "Loss: 0.475 | Acc: 84.170% (8417/10000)\n",
            "\n",
            "Epoch: 37\n",
            "train\n",
            "Loss: 0.324 | Acc: 88.934% (44467/50000)\n",
            "test\n",
            "Loss: 0.544 | Acc: 83.250% (8325/10000)\n",
            "\n",
            "Epoch: 38\n",
            "train\n",
            "Loss: 0.325 | Acc: 88.828% (44414/50000)\n",
            "test\n",
            "Loss: 0.482 | Acc: 84.180% (8418/10000)\n",
            "\n",
            "Epoch: 39\n",
            "train\n",
            "Loss: 0.323 | Acc: 88.938% (44469/50000)\n",
            "test\n",
            "Loss: 0.524 | Acc: 82.760% (8276/10000)\n",
            "\n",
            "Epoch: 40\n",
            "train\n",
            "Loss: 0.316 | Acc: 89.136% (44568/50000)\n",
            "test\n",
            "Loss: 0.535 | Acc: 82.100% (8210/10000)\n",
            "\n",
            "Epoch: 41\n",
            "train\n",
            "Loss: 0.317 | Acc: 89.324% (44662/50000)\n",
            "test\n",
            "Loss: 0.584 | Acc: 81.740% (8174/10000)\n",
            "\n",
            "Epoch: 42\n",
            "train\n",
            "Loss: 0.319 | Acc: 89.206% (44603/50000)\n",
            "test\n",
            "Loss: 0.592 | Acc: 80.470% (8047/10000)\n",
            "\n",
            "Epoch: 43\n",
            "train\n",
            "Loss: 0.307 | Acc: 89.528% (44764/50000)\n",
            "test\n",
            "Loss: 0.758 | Acc: 75.700% (7570/10000)\n",
            "\n",
            "Epoch: 44\n",
            "train\n",
            "Loss: 0.315 | Acc: 89.268% (44634/50000)\n",
            "test\n",
            "Loss: 0.417 | Acc: 86.360% (8636/10000)\n",
            "\n",
            "Epoch: 45\n",
            "train\n",
            "Loss: 0.309 | Acc: 89.474% (44737/50000)\n",
            "test\n",
            "Loss: 0.477 | Acc: 84.280% (8428/10000)\n",
            "\n",
            "Epoch: 46\n",
            "train\n",
            "Loss: 0.312 | Acc: 89.388% (44694/50000)\n",
            "test\n",
            "Loss: 0.375 | Acc: 87.280% (8728/10000)\n",
            "\n",
            "Epoch: 47\n",
            "train\n",
            "Loss: 0.303 | Acc: 89.660% (44830/50000)\n",
            "test\n",
            "Loss: 0.427 | Acc: 86.150% (8615/10000)\n",
            "\n",
            "Epoch: 48\n",
            "train\n",
            "Loss: 0.305 | Acc: 89.590% (44795/50000)\n",
            "test\n",
            "Loss: 0.466 | Acc: 84.900% (8490/10000)\n",
            "\n",
            "Epoch: 49\n",
            "train\n",
            "Loss: 0.302 | Acc: 89.732% (44866/50000)\n",
            "test\n",
            "Loss: 0.508 | Acc: 83.810% (8381/10000)\n",
            "\n",
            "Epoch: 50\n",
            "train\n",
            "Loss: 0.294 | Acc: 90.062% (45031/50000)\n",
            "test\n",
            "Loss: 0.375 | Acc: 87.620% (8762/10000)\n",
            "\n",
            "Epoch: 51\n",
            "train\n",
            "Loss: 0.292 | Acc: 90.164% (45082/50000)\n",
            "test\n",
            "Loss: 0.400 | Acc: 87.050% (8705/10000)\n",
            "\n",
            "Epoch: 52\n",
            "train\n",
            "Loss: 0.292 | Acc: 90.088% (45044/50000)\n",
            "test\n",
            "Loss: 0.421 | Acc: 86.040% (8604/10000)\n",
            "\n",
            "Epoch: 53\n",
            "train\n",
            "Loss: 0.291 | Acc: 89.866% (44933/50000)\n",
            "test\n",
            "Loss: 0.535 | Acc: 82.420% (8242/10000)\n",
            "\n",
            "Epoch: 54\n",
            "train\n",
            "Loss: 0.290 | Acc: 90.154% (45077/50000)\n",
            "test\n",
            "Loss: 0.564 | Acc: 81.970% (8197/10000)\n",
            "\n",
            "Epoch: 55\n",
            "train\n",
            "Loss: 0.285 | Acc: 90.334% (45167/50000)\n",
            "test\n",
            "Loss: 0.406 | Acc: 86.340% (8634/10000)\n",
            "\n",
            "Epoch: 56\n",
            "train\n",
            "Loss: 0.293 | Acc: 89.944% (44972/50000)\n",
            "test\n",
            "Loss: 0.468 | Acc: 85.030% (8503/10000)\n",
            "\n",
            "Epoch: 57\n",
            "train\n",
            "Loss: 0.287 | Acc: 90.166% (45083/50000)\n",
            "test\n",
            "Loss: 0.549 | Acc: 82.730% (8273/10000)\n",
            "\n",
            "Epoch: 58\n",
            "train\n",
            "Loss: 0.286 | Acc: 90.298% (45149/50000)\n",
            "test\n",
            "Loss: 0.348 | Acc: 88.540% (8854/10000)\n",
            "\n",
            "Epoch: 59\n",
            "train\n",
            "Loss: 0.282 | Acc: 90.500% (45250/50000)\n",
            "test\n",
            "Loss: 0.487 | Acc: 83.850% (8385/10000)\n",
            "\n",
            "Epoch: 60\n",
            "train\n",
            "Loss: 0.282 | Acc: 90.362% (45181/50000)\n",
            "test\n",
            "Loss: 0.424 | Acc: 86.510% (8651/10000)\n",
            "\n",
            "Epoch: 61\n",
            "train\n",
            "Loss: 0.279 | Acc: 90.612% (45306/50000)\n",
            "test\n",
            "Loss: 0.382 | Acc: 87.180% (8718/10000)\n",
            "\n",
            "Epoch: 62\n",
            "train\n",
            "Loss: 0.276 | Acc: 90.628% (45314/50000)\n",
            "test\n",
            "Loss: 0.432 | Acc: 85.510% (8551/10000)\n",
            "\n",
            "Epoch: 63\n",
            "train\n",
            "Loss: 0.268 | Acc: 90.882% (45441/50000)\n",
            "test\n",
            "Loss: 0.460 | Acc: 85.220% (8522/10000)\n",
            "\n",
            "Epoch: 64\n",
            "train\n",
            "Loss: 0.273 | Acc: 90.570% (45285/50000)\n",
            "test\n",
            "Loss: 0.371 | Acc: 87.690% (8769/10000)\n",
            "\n",
            "Epoch: 65\n",
            "train\n",
            "Loss: 0.273 | Acc: 90.654% (45327/50000)\n",
            "test\n",
            "Loss: 0.511 | Acc: 84.060% (8406/10000)\n",
            "\n",
            "Epoch: 66\n",
            "train\n",
            "Loss: 0.268 | Acc: 90.960% (45480/50000)\n",
            "test\n",
            "Loss: 0.495 | Acc: 85.130% (8513/10000)\n",
            "\n",
            "Epoch: 67\n",
            "train\n",
            "Loss: 0.263 | Acc: 91.086% (45543/50000)\n",
            "test\n",
            "Loss: 0.358 | Acc: 88.360% (8836/10000)\n",
            "\n",
            "Epoch: 68\n",
            "train\n",
            "Loss: 0.261 | Acc: 90.938% (45469/50000)\n",
            "test\n",
            "Loss: 0.524 | Acc: 82.690% (8269/10000)\n",
            "\n",
            "Epoch: 69\n",
            "train\n",
            "Loss: 0.260 | Acc: 91.172% (45586/50000)\n",
            "test\n",
            "Loss: 0.399 | Acc: 86.640% (8664/10000)\n",
            "\n",
            "Epoch: 70\n",
            "train\n",
            "Loss: 0.257 | Acc: 91.226% (45613/50000)\n",
            "test\n",
            "Loss: 0.364 | Acc: 87.780% (8778/10000)\n",
            "\n",
            "Epoch: 71\n",
            "train\n",
            "Loss: 0.257 | Acc: 91.230% (45615/50000)\n",
            "test\n",
            "Loss: 0.396 | Acc: 86.980% (8698/10000)\n",
            "\n",
            "Epoch: 72\n",
            "train\n",
            "Loss: 0.253 | Acc: 91.292% (45646/50000)\n",
            "test\n",
            "Loss: 0.376 | Acc: 87.590% (8759/10000)\n",
            "\n",
            "Epoch: 73\n",
            "train\n",
            "Loss: 0.251 | Acc: 91.508% (45754/50000)\n",
            "test\n",
            "Loss: 0.413 | Acc: 87.080% (8708/10000)\n",
            "\n",
            "Epoch: 74\n",
            "train\n",
            "Loss: 0.251 | Acc: 91.352% (45676/50000)\n",
            "test\n",
            "Loss: 0.414 | Acc: 86.400% (8640/10000)\n",
            "\n",
            "Epoch: 75\n",
            "train\n",
            "Loss: 0.250 | Acc: 91.504% (45752/50000)\n",
            "test\n",
            "Loss: 0.344 | Acc: 88.990% (8899/10000)\n",
            "\n",
            "Epoch: 76\n",
            "train\n",
            "Loss: 0.243 | Acc: 91.600% (45800/50000)\n",
            "test\n",
            "Loss: 0.590 | Acc: 80.890% (8089/10000)\n",
            "\n",
            "Epoch: 77\n",
            "train\n",
            "Loss: 0.243 | Acc: 91.698% (45849/50000)\n",
            "test\n",
            "Loss: 0.489 | Acc: 84.300% (8430/10000)\n",
            "\n",
            "Epoch: 78\n",
            "train\n",
            "Loss: 0.243 | Acc: 91.608% (45804/50000)\n",
            "test\n",
            "Loss: 0.375 | Acc: 87.690% (8769/10000)\n",
            "\n",
            "Epoch: 79\n",
            "train\n",
            "Loss: 0.239 | Acc: 91.898% (45949/50000)\n",
            "test\n",
            "Loss: 0.411 | Acc: 86.940% (8694/10000)\n",
            "\n",
            "Epoch: 80\n",
            "train\n",
            "Loss: 0.232 | Acc: 92.020% (46010/50000)\n",
            "test\n",
            "Loss: 0.350 | Acc: 88.250% (8825/10000)\n",
            "\n",
            "Epoch: 81\n",
            "train\n",
            "Loss: 0.239 | Acc: 91.802% (45901/50000)\n",
            "test\n",
            "Loss: 0.352 | Acc: 88.680% (8868/10000)\n",
            "\n",
            "Epoch: 82\n",
            "train\n",
            "Loss: 0.234 | Acc: 92.054% (46027/50000)\n",
            "test\n",
            "Loss: 0.353 | Acc: 88.520% (8852/10000)\n",
            "\n",
            "Epoch: 83\n",
            "train\n",
            "Loss: 0.227 | Acc: 92.198% (46099/50000)\n",
            "test\n",
            "Loss: 0.410 | Acc: 86.890% (8689/10000)\n",
            "\n",
            "Epoch: 84\n",
            "train\n",
            "Loss: 0.228 | Acc: 92.126% (46063/50000)\n",
            "test\n",
            "Loss: 0.388 | Acc: 87.370% (8737/10000)\n",
            "\n",
            "Epoch: 85\n",
            "train\n",
            "Loss: 0.229 | Acc: 92.218% (46109/50000)\n",
            "test\n",
            "Loss: 0.394 | Acc: 87.260% (8726/10000)\n",
            "\n",
            "Epoch: 86\n",
            "train\n",
            "Loss: 0.227 | Acc: 92.242% (46121/50000)\n",
            "test\n",
            "Loss: 0.402 | Acc: 87.090% (8709/10000)\n",
            "\n",
            "Epoch: 87\n",
            "train\n",
            "Loss: 0.223 | Acc: 92.292% (46146/50000)\n",
            "test\n",
            "Loss: 0.339 | Acc: 88.770% (8877/10000)\n",
            "\n",
            "Epoch: 88\n",
            "train\n",
            "Loss: 0.211 | Acc: 92.858% (46429/50000)\n",
            "test\n",
            "Loss: 0.416 | Acc: 86.500% (8650/10000)\n",
            "\n",
            "Epoch: 89\n",
            "train\n",
            "Loss: 0.218 | Acc: 92.532% (46266/50000)\n",
            "test\n",
            "Loss: 0.419 | Acc: 86.540% (8654/10000)\n",
            "\n",
            "Epoch: 90\n",
            "train\n",
            "Loss: 0.217 | Acc: 92.522% (46261/50000)\n",
            "test\n",
            "Loss: 0.478 | Acc: 84.650% (8465/10000)\n",
            "\n",
            "Epoch: 91\n",
            "train\n",
            "Loss: 0.213 | Acc: 92.658% (46329/50000)\n",
            "test\n",
            "Loss: 0.384 | Acc: 87.890% (8789/10000)\n",
            "\n",
            "Epoch: 92\n",
            "train\n",
            "Loss: 0.206 | Acc: 92.968% (46484/50000)\n",
            "test\n",
            "Loss: 0.374 | Acc: 88.120% (8812/10000)\n",
            "\n",
            "Epoch: 93\n",
            "train\n",
            "Loss: 0.210 | Acc: 92.844% (46422/50000)\n",
            "test\n",
            "Loss: 0.398 | Acc: 87.160% (8716/10000)\n",
            "\n",
            "Epoch: 94\n",
            "train\n",
            "Loss: 0.201 | Acc: 93.064% (46532/50000)\n",
            "test\n",
            "Loss: 0.307 | Acc: 89.880% (8988/10000)\n",
            "\n",
            "Epoch: 95\n",
            "train\n",
            "Loss: 0.205 | Acc: 92.964% (46482/50000)\n",
            "test\n",
            "Loss: 0.313 | Acc: 89.960% (8996/10000)\n",
            "\n",
            "Epoch: 96\n",
            "train\n",
            "Loss: 0.195 | Acc: 93.336% (46668/50000)\n",
            "test\n",
            "Loss: 0.383 | Acc: 87.670% (8767/10000)\n",
            "\n",
            "Epoch: 97\n",
            "train\n",
            "Loss: 0.193 | Acc: 93.474% (46737/50000)\n",
            "test\n",
            "Loss: 0.308 | Acc: 89.760% (8976/10000)\n",
            "\n",
            "Epoch: 98\n",
            "train\n",
            "Loss: 0.195 | Acc: 93.318% (46659/50000)\n",
            "test\n",
            "Loss: 0.323 | Acc: 89.480% (8948/10000)\n",
            "\n",
            "Epoch: 99\n",
            "train\n",
            "Loss: 0.193 | Acc: 93.324% (46662/50000)\n",
            "test\n",
            "Loss: 0.345 | Acc: 88.750% (8875/10000)\n",
            "\n",
            "Epoch: 100\n",
            "train\n",
            "Loss: 0.185 | Acc: 93.672% (46836/50000)\n",
            "test\n",
            "Loss: 0.381 | Acc: 88.280% (8828/10000)\n",
            "\n",
            "Epoch: 101\n",
            "train\n",
            "Loss: 0.185 | Acc: 93.666% (46833/50000)\n",
            "test\n",
            "Loss: 0.368 | Acc: 88.170% (8817/10000)\n",
            "\n",
            "Epoch: 102\n",
            "train\n",
            "Loss: 0.185 | Acc: 93.632% (46816/50000)\n",
            "test\n",
            "Loss: 0.340 | Acc: 89.060% (8906/10000)\n",
            "\n",
            "Epoch: 103\n",
            "train\n",
            "Loss: 0.177 | Acc: 93.934% (46967/50000)\n",
            "test\n",
            "Loss: 0.342 | Acc: 89.080% (8908/10000)\n",
            "\n",
            "Epoch: 104\n",
            "train\n",
            "Loss: 0.177 | Acc: 93.940% (46970/50000)\n",
            "test\n",
            "Loss: 0.385 | Acc: 87.830% (8783/10000)\n",
            "\n",
            "Epoch: 105\n",
            "train\n",
            "Loss: 0.178 | Acc: 93.938% (46969/50000)\n",
            "test\n",
            "Loss: 0.377 | Acc: 87.980% (8798/10000)\n",
            "\n",
            "Epoch: 106\n",
            "train\n",
            "Loss: 0.174 | Acc: 94.030% (47015/50000)\n",
            "test\n",
            "Loss: 0.332 | Acc: 89.380% (8938/10000)\n",
            "\n",
            "Epoch: 107\n",
            "train\n",
            "Loss: 0.172 | Acc: 94.188% (47094/50000)\n",
            "test\n",
            "Loss: 0.404 | Acc: 87.650% (8765/10000)\n",
            "\n",
            "Epoch: 108\n",
            "train\n",
            "Loss: 0.165 | Acc: 94.450% (47225/50000)\n",
            "test\n",
            "Loss: 0.412 | Acc: 86.730% (8673/10000)\n",
            "\n",
            "Epoch: 109\n",
            "train\n",
            "Loss: 0.165 | Acc: 94.332% (47166/50000)\n",
            "test\n",
            "Loss: 0.298 | Acc: 90.490% (9049/10000)\n",
            "\n",
            "Epoch: 110\n",
            "train\n",
            "Loss: 0.160 | Acc: 94.504% (47252/50000)\n",
            "test\n",
            "Loss: 0.273 | Acc: 90.840% (9084/10000)\n",
            "\n",
            "Epoch: 111\n",
            "train\n",
            "Loss: 0.163 | Acc: 94.482% (47241/50000)\n",
            "test\n",
            "Loss: 0.308 | Acc: 89.850% (8985/10000)\n",
            "\n",
            "Epoch: 112\n",
            "train\n",
            "Loss: 0.148 | Acc: 94.986% (47493/50000)\n",
            "test\n",
            "Loss: 0.332 | Acc: 89.730% (8973/10000)\n",
            "\n",
            "Epoch: 113\n",
            "train\n",
            "Loss: 0.150 | Acc: 94.816% (47408/50000)\n",
            "test\n",
            "Loss: 0.324 | Acc: 89.530% (8953/10000)\n",
            "\n",
            "Epoch: 114\n",
            "train\n",
            "Loss: 0.151 | Acc: 94.802% (47401/50000)\n",
            "test\n",
            "Loss: 0.386 | Acc: 88.230% (8823/10000)\n",
            "\n",
            "Epoch: 115\n",
            "train\n",
            "Loss: 0.146 | Acc: 95.026% (47513/50000)\n",
            "test\n",
            "Loss: 0.340 | Acc: 89.500% (8950/10000)\n",
            "\n",
            "Epoch: 116\n",
            "train\n",
            "Loss: 0.145 | Acc: 95.158% (47579/50000)\n",
            "test\n",
            "Loss: 0.335 | Acc: 89.660% (8966/10000)\n",
            "\n",
            "Epoch: 117\n",
            "train\n",
            "Loss: 0.141 | Acc: 95.172% (47586/50000)\n",
            "test\n",
            "Loss: 0.320 | Acc: 90.180% (9018/10000)\n",
            "\n",
            "Epoch: 118\n",
            "train\n",
            "Loss: 0.138 | Acc: 95.310% (47655/50000)\n",
            "test\n",
            "Loss: 0.304 | Acc: 90.240% (9024/10000)\n",
            "\n",
            "Epoch: 119\n",
            "train\n",
            "Loss: 0.139 | Acc: 95.316% (47658/50000)\n",
            "test\n",
            "Loss: 0.303 | Acc: 90.680% (9068/10000)\n",
            "\n",
            "Epoch: 120\n",
            "train\n",
            "Loss: 0.132 | Acc: 95.590% (47795/50000)\n",
            "test\n",
            "Loss: 0.291 | Acc: 91.120% (9112/10000)\n",
            "\n",
            "Epoch: 121\n",
            "train\n",
            "Loss: 0.130 | Acc: 95.504% (47752/50000)\n",
            "test\n",
            "Loss: 0.335 | Acc: 89.810% (8981/10000)\n",
            "\n",
            "Epoch: 122\n",
            "train\n",
            "Loss: 0.126 | Acc: 95.750% (47875/50000)\n",
            "test\n",
            "Loss: 0.319 | Acc: 90.350% (9035/10000)\n",
            "\n",
            "Epoch: 123\n",
            "train\n",
            "Loss: 0.123 | Acc: 95.740% (47870/50000)\n",
            "test\n",
            "Loss: 0.283 | Acc: 90.880% (9088/10000)\n",
            "\n",
            "Epoch: 124\n",
            "train\n",
            "Loss: 0.118 | Acc: 95.972% (47986/50000)\n",
            "test\n",
            "Loss: 0.318 | Acc: 90.390% (9039/10000)\n",
            "\n",
            "Epoch: 125\n",
            "train\n",
            "Loss: 0.117 | Acc: 95.968% (47984/50000)\n",
            "test\n",
            "Loss: 0.269 | Acc: 91.730% (9173/10000)\n",
            "\n",
            "Epoch: 126\n",
            "train\n",
            "Loss: 0.113 | Acc: 96.190% (48095/50000)\n",
            "test\n",
            "Loss: 0.290 | Acc: 90.850% (9085/10000)\n",
            "\n",
            "Epoch: 127\n",
            "train\n",
            "Loss: 0.114 | Acc: 96.132% (48066/50000)\n",
            "test\n",
            "Loss: 0.287 | Acc: 90.860% (9086/10000)\n",
            "\n",
            "Epoch: 128\n",
            "train\n",
            "Loss: 0.106 | Acc: 96.398% (48199/50000)\n",
            "test\n",
            "Loss: 0.305 | Acc: 90.920% (9092/10000)\n",
            "\n",
            "Epoch: 129\n",
            "train\n",
            "Loss: 0.107 | Acc: 96.376% (48188/50000)\n",
            "test\n",
            "Loss: 0.296 | Acc: 90.860% (9086/10000)\n",
            "\n",
            "Epoch: 130\n",
            "train\n",
            "Loss: 0.098 | Acc: 96.582% (48291/50000)\n",
            "test\n",
            "Loss: 0.286 | Acc: 91.590% (9159/10000)\n",
            "\n",
            "Epoch: 131\n",
            "train\n",
            "Loss: 0.101 | Acc: 96.520% (48260/50000)\n",
            "test\n",
            "Loss: 0.322 | Acc: 90.180% (9018/10000)\n",
            "\n",
            "Epoch: 132\n",
            "train\n",
            "Loss: 0.099 | Acc: 96.684% (48342/50000)\n",
            "test\n",
            "Loss: 0.274 | Acc: 91.550% (9155/10000)\n",
            "\n",
            "Epoch: 133\n",
            "train\n",
            "Loss: 0.097 | Acc: 96.774% (48387/50000)\n",
            "test\n",
            "Loss: 0.281 | Acc: 91.560% (9156/10000)\n",
            "\n",
            "Epoch: 134\n",
            "train\n",
            "Loss: 0.088 | Acc: 97.014% (48507/50000)\n",
            "test\n",
            "Loss: 0.298 | Acc: 91.100% (9110/10000)\n",
            "\n",
            "Epoch: 135\n",
            "train\n",
            "Loss: 0.088 | Acc: 97.076% (48538/50000)\n",
            "test\n",
            "Loss: 0.292 | Acc: 91.280% (9128/10000)\n",
            "\n",
            "Epoch: 136\n",
            "train\n",
            "Loss: 0.081 | Acc: 97.286% (48643/50000)\n",
            "test\n",
            "Loss: 0.270 | Acc: 92.100% (9210/10000)\n",
            "\n",
            "Epoch: 137\n",
            "train\n",
            "Loss: 0.084 | Acc: 97.248% (48624/50000)\n",
            "test\n",
            "Loss: 0.289 | Acc: 91.510% (9151/10000)\n",
            "\n",
            "Epoch: 138\n",
            "train\n",
            "Loss: 0.079 | Acc: 97.362% (48681/50000)\n",
            "test\n",
            "Loss: 0.278 | Acc: 91.680% (9168/10000)\n",
            "\n",
            "Epoch: 139\n",
            "train\n",
            "Loss: 0.078 | Acc: 97.418% (48709/50000)\n",
            "test\n",
            "Loss: 0.287 | Acc: 91.670% (9167/10000)\n",
            "\n",
            "Epoch: 140\n",
            "train\n",
            "Loss: 0.074 | Acc: 97.526% (48763/50000)\n",
            "test\n",
            "Loss: 0.335 | Acc: 90.590% (9059/10000)\n",
            "\n",
            "Epoch: 141\n",
            "train\n",
            "Loss: 0.070 | Acc: 97.658% (48829/50000)\n",
            "test\n",
            "Loss: 0.349 | Acc: 90.390% (9039/10000)\n",
            "\n",
            "Epoch: 142\n",
            "train\n",
            "Loss: 0.070 | Acc: 97.638% (48819/50000)\n",
            "test\n",
            "Loss: 0.277 | Acc: 92.210% (9221/10000)\n",
            "\n",
            "Epoch: 143\n",
            "train\n",
            "Loss: 0.063 | Acc: 97.928% (48964/50000)\n",
            "test\n",
            "Loss: 0.273 | Acc: 92.310% (9231/10000)\n",
            "\n",
            "Epoch: 144\n",
            "train\n",
            "Loss: 0.065 | Acc: 97.772% (48886/50000)\n",
            "test\n",
            "Loss: 0.269 | Acc: 92.170% (9217/10000)\n",
            "\n",
            "Epoch: 145\n",
            "train\n",
            "Loss: 0.059 | Acc: 98.012% (49006/50000)\n",
            "test\n",
            "Loss: 0.329 | Acc: 90.650% (9065/10000)\n",
            "\n",
            "Epoch: 146\n",
            "train\n",
            "Loss: 0.058 | Acc: 98.000% (49000/50000)\n",
            "test\n",
            "Loss: 0.262 | Acc: 92.340% (9234/10000)\n",
            "\n",
            "Epoch: 147\n",
            "train\n",
            "Loss: 0.051 | Acc: 98.310% (49155/50000)\n",
            "test\n",
            "Loss: 0.264 | Acc: 92.680% (9268/10000)\n",
            "\n",
            "Epoch: 148\n",
            "train\n",
            "Loss: 0.058 | Acc: 98.174% (49087/50000)\n",
            "test\n",
            "Loss: 0.242 | Acc: 92.860% (9286/10000)\n",
            "\n",
            "Epoch: 149\n",
            "train\n",
            "Loss: 0.043 | Acc: 98.624% (49312/50000)\n",
            "test\n",
            "Loss: 0.274 | Acc: 92.610% (9261/10000)\n",
            "\n",
            "Epoch: 150\n",
            "train\n",
            "Loss: 0.047 | Acc: 98.460% (49230/50000)\n",
            "test\n",
            "Loss: 0.252 | Acc: 92.930% (9293/10000)\n",
            "\n",
            "Epoch: 151\n",
            "train\n",
            "Loss: 0.039 | Acc: 98.734% (49367/50000)\n",
            "test\n",
            "Loss: 0.270 | Acc: 92.460% (9246/10000)\n",
            "\n",
            "Epoch: 152\n",
            "train\n",
            "Loss: 0.041 | Acc: 98.664% (49332/50000)\n",
            "test\n",
            "Loss: 0.249 | Acc: 93.130% (9313/10000)\n",
            "\n",
            "Epoch: 153\n",
            "train\n",
            "Loss: 0.036 | Acc: 98.894% (49447/50000)\n",
            "test\n",
            "Loss: 0.236 | Acc: 93.340% (9334/10000)\n",
            "\n",
            "Epoch: 154\n",
            "train\n",
            "Loss: 0.034 | Acc: 98.916% (49458/50000)\n",
            "test\n",
            "Loss: 0.260 | Acc: 92.980% (9298/10000)\n",
            "\n",
            "Epoch: 155\n",
            "train\n",
            "Loss: 0.029 | Acc: 99.090% (49545/50000)\n",
            "test\n",
            "Loss: 0.244 | Acc: 93.330% (9333/10000)\n",
            "\n",
            "Epoch: 156\n",
            "train\n",
            "Loss: 0.025 | Acc: 99.236% (49618/50000)\n",
            "test\n",
            "Loss: 0.243 | Acc: 93.460% (9346/10000)\n",
            "\n",
            "Epoch: 157\n",
            "train\n",
            "Loss: 0.027 | Acc: 99.202% (49601/50000)\n",
            "test\n",
            "Loss: 0.219 | Acc: 93.820% (9382/10000)\n",
            "\n",
            "Epoch: 158\n",
            "train\n",
            "Loss: 0.022 | Acc: 99.324% (49662/50000)\n",
            "test\n",
            "Loss: 0.231 | Acc: 93.910% (9391/10000)\n",
            "\n",
            "Epoch: 159\n",
            "train\n",
            "Loss: 0.022 | Acc: 99.294% (49647/50000)\n",
            "test\n",
            "Loss: 0.233 | Acc: 93.470% (9347/10000)\n",
            "\n",
            "Epoch: 160\n",
            "train\n",
            "Loss: 0.022 | Acc: 99.324% (49662/50000)\n",
            "test\n",
            "Loss: 0.227 | Acc: 93.650% (9365/10000)\n",
            "\n",
            "Epoch: 161\n",
            "train\n",
            "Loss: 0.019 | Acc: 99.390% (49695/50000)\n",
            "test\n",
            "Loss: 0.231 | Acc: 93.790% (9379/10000)\n",
            "\n",
            "Epoch: 162\n",
            "train\n",
            "Loss: 0.015 | Acc: 99.532% (49766/50000)\n",
            "test\n",
            "Loss: 0.237 | Acc: 93.910% (9391/10000)\n",
            "\n",
            "Epoch: 163\n",
            "train\n",
            "Loss: 0.014 | Acc: 99.602% (49801/50000)\n",
            "test\n",
            "Loss: 0.223 | Acc: 94.240% (9424/10000)\n",
            "\n",
            "Epoch: 164\n",
            "train\n",
            "Loss: 0.011 | Acc: 99.702% (49851/50000)\n",
            "test\n",
            "Loss: 0.217 | Acc: 94.370% (9437/10000)\n",
            "\n",
            "Epoch: 165\n",
            "train\n",
            "Loss: 0.010 | Acc: 99.740% (49870/50000)\n",
            "test\n",
            "Loss: 0.220 | Acc: 94.520% (9452/10000)\n",
            "\n",
            "Epoch: 166\n",
            "train\n",
            "Loss: 0.009 | Acc: 99.754% (49877/50000)\n",
            "test\n",
            "Loss: 0.222 | Acc: 94.440% (9444/10000)\n",
            "\n",
            "Epoch: 167\n",
            "train\n",
            "Loss: 0.008 | Acc: 99.804% (49902/50000)\n",
            "test\n",
            "Loss: 0.203 | Acc: 94.650% (9465/10000)\n",
            "\n",
            "Epoch: 168\n",
            "train\n",
            "Loss: 0.009 | Acc: 99.760% (49880/50000)\n",
            "test\n",
            "Loss: 0.209 | Acc: 94.790% (9479/10000)\n",
            "\n",
            "Epoch: 169\n",
            "train\n",
            "Loss: 0.006 | Acc: 99.848% (49924/50000)\n",
            "test\n",
            "Loss: 0.196 | Acc: 95.000% (9500/10000)\n",
            "\n",
            "Epoch: 170\n",
            "train\n",
            "Loss: 0.005 | Acc: 99.890% (49945/50000)\n",
            "test\n",
            "Loss: 0.203 | Acc: 94.710% (9471/10000)\n",
            "\n",
            "Epoch: 171\n",
            "train\n",
            "Loss: 0.004 | Acc: 99.930% (49965/50000)\n",
            "test\n",
            "Loss: 0.197 | Acc: 94.990% (9499/10000)\n",
            "\n",
            "Epoch: 172\n",
            "train\n",
            "Loss: 0.003 | Acc: 99.948% (49974/50000)\n",
            "test\n",
            "Loss: 0.196 | Acc: 95.150% (9515/10000)\n",
            "\n",
            "Epoch: 173\n",
            "train\n",
            "Loss: 0.003 | Acc: 99.950% (49975/50000)\n",
            "test\n",
            "Loss: 0.191 | Acc: 95.260% (9526/10000)\n",
            "\n",
            "Epoch: 174\n",
            "train\n",
            "Loss: 0.003 | Acc: 99.974% (49987/50000)\n",
            "test\n",
            "Loss: 0.187 | Acc: 95.240% (9524/10000)\n",
            "\n",
            "Epoch: 175\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.974% (49987/50000)\n",
            "test\n",
            "Loss: 0.188 | Acc: 95.380% (9538/10000)\n",
            "\n",
            "Epoch: 176\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.972% (49986/50000)\n",
            "test\n",
            "Loss: 0.185 | Acc: 95.260% (9526/10000)\n",
            "\n",
            "Epoch: 177\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.976% (49988/50000)\n",
            "test\n",
            "Loss: 0.181 | Acc: 95.390% (9539/10000)\n",
            "\n",
            "Epoch: 178\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.982% (49991/50000)\n",
            "test\n",
            "Loss: 0.179 | Acc: 95.480% (9548/10000)\n",
            "\n",
            "Epoch: 179\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.982% (49991/50000)\n",
            "test\n",
            "Loss: 0.178 | Acc: 95.430% (9543/10000)\n",
            "\n",
            "Epoch: 180\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.992% (49996/50000)\n",
            "test\n",
            "Loss: 0.178 | Acc: 95.490% (9549/10000)\n",
            "\n",
            "Epoch: 181\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.984% (49992/50000)\n",
            "test\n",
            "Loss: 0.182 | Acc: 95.290% (9529/10000)\n",
            "\n",
            "Epoch: 182\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.994% (49997/50000)\n",
            "test\n",
            "Loss: 0.175 | Acc: 95.520% (9552/10000)\n",
            "\n",
            "Epoch: 183\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.988% (49994/50000)\n",
            "test\n",
            "Loss: 0.175 | Acc: 95.440% (9544/10000)\n",
            "\n",
            "Epoch: 184\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.994% (49997/50000)\n",
            "test\n",
            "Loss: 0.176 | Acc: 95.510% (9551/10000)\n",
            "\n",
            "Epoch: 185\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.996% (49998/50000)\n",
            "test\n",
            "Loss: 0.175 | Acc: 95.710% (9571/10000)\n",
            "\n",
            "Epoch: 186\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.992% (49996/50000)\n",
            "test\n",
            "Loss: 0.172 | Acc: 95.470% (9547/10000)\n",
            "\n",
            "Epoch: 187\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.988% (49994/50000)\n",
            "test\n",
            "Loss: 0.174 | Acc: 95.560% (9556/10000)\n",
            "\n",
            "Epoch: 188\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.992% (49996/50000)\n",
            "test\n",
            "Loss: 0.172 | Acc: 95.470% (9547/10000)\n",
            "\n",
            "Epoch: 189\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.994% (49997/50000)\n",
            "test\n",
            "Loss: 0.172 | Acc: 95.590% (9559/10000)\n",
            "\n",
            "Epoch: 190\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.998% (49999/50000)\n",
            "test\n",
            "Loss: 0.172 | Acc: 95.550% (9555/10000)\n",
            "\n",
            "Epoch: 191\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.996% (49998/50000)\n",
            "test\n",
            "Loss: 0.171 | Acc: 95.500% (9550/10000)\n",
            "\n",
            "Epoch: 192\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.994% (49997/50000)\n",
            "test\n",
            "Loss: 0.171 | Acc: 95.500% (9550/10000)\n",
            "\n",
            "Epoch: 193\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.992% (49996/50000)\n",
            "test\n",
            "Loss: 0.172 | Acc: 95.550% (9555/10000)\n",
            "\n",
            "Epoch: 194\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.996% (49998/50000)\n",
            "test\n",
            "Loss: 0.171 | Acc: 95.510% (9551/10000)\n",
            "\n",
            "Epoch: 195\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.998% (49999/50000)\n",
            "test\n",
            "Loss: 0.171 | Acc: 95.540% (9554/10000)\n",
            "\n",
            "Epoch: 196\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.998% (49999/50000)\n",
            "test\n",
            "Loss: 0.171 | Acc: 95.570% (9557/10000)\n",
            "\n",
            "Epoch: 197\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.996% (49998/50000)\n",
            "test\n",
            "Loss: 0.170 | Acc: 95.550% (9555/10000)\n",
            "\n",
            "Epoch: 198\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.994% (49997/50000)\n",
            "test\n",
            "Loss: 0.171 | Acc: 95.540% (9554/10000)\n",
            "\n",
            "Epoch: 199\n",
            "train\n",
            "Loss: 0.002 | Acc: 99.996% (49998/50000)\n",
            "test\n",
            "Loss: 0.173 | Acc: 95.470% (9547/10000)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    print('train')\n",
        "    print('Loss: %.3f | Acc: %.3f%% (%d/%d)'% (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    print('test')\n",
        "    print('Loss: %.3f | Acc: %.3f%% (%d/%d)'% (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + 200):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "vgg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fb416e92e2a4f78a8fb625e6b89026d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "370bab8a7834477d92bf69b4d419d8c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3baa6f62b034472e803a6ba58e4440d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75451fb9889d460badc555832b180867",
            "placeholder": "​",
            "style": "IPY_MODEL_b8528f587020461d95979131c341f1ab",
            "value": " 170499072/? [00:05&lt;00:00, 32689905.51it/s]"
          }
        },
        "4307047c16b248a8a5d67c62459befdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4530906ace054be1a6cd62884698b235": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbc819a692fb4a7f8bcb67713e323b02",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e050d161f3cb412aa677ababd693ebff",
            "value": 170498071
          }
        },
        "5bd88bb3c6be4c7d89c47492e2cd32f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb416e92e2a4f78a8fb625e6b89026d",
            "placeholder": "​",
            "style": "IPY_MODEL_4307047c16b248a8a5d67c62459befdb",
            "value": ""
          }
        },
        "75451fb9889d460badc555832b180867": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8528f587020461d95979131c341f1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7e183e0ea0142debf3be71f9c119172": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bd88bb3c6be4c7d89c47492e2cd32f8",
              "IPY_MODEL_4530906ace054be1a6cd62884698b235",
              "IPY_MODEL_3baa6f62b034472e803a6ba58e4440d1"
            ],
            "layout": "IPY_MODEL_370bab8a7834477d92bf69b4d419d8c6"
          }
        },
        "dbc819a692fb4a7f8bcb67713e323b02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e050d161f3cb412aa677ababd693ebff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
